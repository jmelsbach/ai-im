{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmelsbach/ai-im/blob/main/notebooks/Exercises/01%20-%20Neural%20Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRThsIUzjQJK"
      },
      "source": [
        "# A simple Neural Network with Pytorch\n",
        "PyTorch is an open-source machine learning framework and is widely used in research and in production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XORXq6u1ldMk"
      },
      "source": [
        "In this notebook you will learn how to create a Neural Network with Pytorch that is able classify hand-written digits and does this with an accuracy of over 97%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGJ5cjQ5I5EE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2ujOmatdvKZ"
      },
      "source": [
        "There are four required building blocks when it comes to training a neural network:\n",
        "* Data\n",
        "* Model\n",
        "* Loss Function \n",
        "* Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54KiCaZTpmNe"
      },
      "source": [
        "## Data\n",
        "First of all we need data to train our network on. In the real world collecting and processing data is a very time consuming process. Luckily for us the research community published a lot of high quality datasets in the past that are ready to use for us.\n",
        "\n",
        "In this notebook we will use the famous MNIST Dataset which consists of several thousand instances of handwritten digits with their coresponding labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzne7Bb6rbLc"
      },
      "source": [
        " We download the dataset via the sklearn library. So we need to import sklearn and download the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJPj8VMZtLgY"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvXy3tk7tTFo"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "463VuprVx0g9"
      },
      "source": [
        " We downloaded the dataset and saved created the variables `X` containing the pictures and `y` containing the labels. Let's have a closer look at the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWVva0tEx2Fz"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axcx7IV71srW"
      },
      "source": [
        "`.shape` is a very useful command to see the dimensions of a vector or matrix. As we can see the shape of y is `(70000,)` which basically means it is a vector with 70000 rows. This means that we have 70000 labels and therefore 70000 examples in our dataset. Let's have a look at the first label:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LdyWe9J2hC8"
      },
      "outputs": [],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxBSw-ad2j6D"
      },
      "source": [
        "Next we look at the pictures of the digits which are stored in the `X` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFxJBd-b7T8c"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfpDUNKz7VND"
      },
      "source": [
        "The first dimension looks familiar. We had 70000 labels so it definitly makes sense to have 70000 images as well. You might have expected a three dimensional variable here, because images are a matrix of pixels. In this dataset the pictures are flattend into vectors with 784 dimensions. The original size of the images are 28x28 Pixels. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEfSPsKo8bP2"
      },
      "source": [
        "If we want to look at the first picture of the dataset we have to reshape the images into a 28 by 28 matrix. We use `mathplotlib.pyplot.imshow()` to visualize the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoBQrX3-8nX6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icLYWWFN9Jkh"
      },
      "outputs": [],
      "source": [
        "x0 = X[0]\n",
        "x0 = x0.reshape([28,28])\n",
        "x0.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyNozJ67vb8r"
      },
      "source": [
        "As you can see above currently the values range from 0 to 255. In Deep Learning we almost always want to have our input values to range from 0 to 1 instead. Scaling the data is very easy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZEa4oE5v-ye"
      },
      "outputs": [],
      "source": [
        "X = X / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAYrsRp98utC"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x0.reshape(28,28), cmap='Greys')\n",
        "# print the corresponding label\n",
        "print(\"Label: \", y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUFcifqWD800"
      },
      "source": [
        "### Datasets and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1z98-I7ENWo"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4Q8WyQOLA6-"
      },
      "outputs": [],
      "source": [
        "y = y.astype('int8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcOmKlbuECL5"
      },
      "outputs": [],
      "source": [
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X).float() / 255.\n",
        "        self.y = torch.tensor(y).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        return (self.X[index], self.y[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRHka79J8QB7"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAVUKtExKRoa"
      },
      "outputs": [],
      "source": [
        "mnist_train = MNISTDataset(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kqyr0AwP8QB7"
      },
      "outputs": [],
      "source": [
        "mnist_test = MNISTDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aENWR3D5zSRh"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(mnist_train, batch_size=128) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXjhJnno8QB7"
      },
      "outputs": [],
      "source": [
        "test_dl = DataLoader(mnist_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt9LXoqJ8ziZ"
      },
      "source": [
        "## The Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqTTBvoo15DA"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HGwx54BlSxr"
      },
      "outputs": [],
      "source": [
        "class NeuralNetworkV1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetworkV1, self).__init__()\n",
        "        self.l1 = nn.Linear(784,500)\n",
        "        self.l2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.l1(X))\n",
        "        X = self.l2(X)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-x1P9_EtK1d"
      },
      "outputs": [],
      "source": [
        "net1 = NeuralNetworkV1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxEtVK3TtPpb"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "output = net1(mnist_train[0][0])\n",
        "print(output)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W26Wn4yQtWej"
      },
      "source": [
        "This was one forward pass through our neural network. We get an output of shape `[10]` but of quite random positive and negative numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfoFbLW4qsgz"
      },
      "source": [
        "Instead of random numbers we want our network to output a probability distribution, where hopefully the correct number has the highest probability. We have to modify our output in a way that it outputs probabilities, which implies to properties:\n",
        "1. Each output *must* be between `0` and `1`\n",
        "2. All outputs have to add up to `1` in total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_1-6kfBqsI0"
      },
      "source": [
        "ðŸ’­ Think a moment why all outputs have to add up to `1` in our the digit classification example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l266WhblQtg4"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "    return x.exp() / x.exp().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edOm-wdgs7YM"
      },
      "outputs": [],
      "source": [
        "class NeuralNetworkV2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetworkV2, self).__init__()\n",
        "        self.l1 = nn.Linear(784,200)\n",
        "        self.l2 = nn.Linear(200, 10)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = F.sigmoid(self.l1(X))\n",
        "        X = self.l2(X)\n",
        "        \n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrjB-OlWQAWg"
      },
      "source": [
        "$$\n",
        "\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DeAK_txv9fp"
      },
      "outputs": [],
      "source": [
        "net2 = NeuralNetworkV2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2iTVPDswV6Y"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "output = net2(torch.tensor(X[0]).float() / 256)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFc8s4KGwhK8"
      },
      "source": [
        "As you can see we reached our goal. Every output is a number between zero and one and all outputs add up to 1. However, all outputs probabilities are about the same at about `0.1`. Which basically means that our network has no idea which digit is shown here. And how should it? It hasn't learned anything yet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np86sSe8uF-W"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPThpxBeuLmV"
      },
      "source": [
        "We need a way to see how good or how bad our neural net is doing. When you take a look in the documentation of the `nn.CrossEntropyLoss()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haNzck4M8QB8"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2J-oBSv8QB8"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07QD6Rgr8QB8"
      },
      "outputs": [],
      "source": [
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZJB8vqs8QB8"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(net2.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxG4ZVBc8QB8"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7UoXE9T8QB8"
      },
      "outputs": [],
      "source": [
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQyVAVU_8QB8"
      },
      "outputs": [],
      "source": [
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrTUcM4b8QB8"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "    net2.train()\n",
        "    total_loss = 0\n",
        "    train_acc = 0\n",
        "    for inputs, labels in train_dl:\n",
        "        \n",
        "        preds = net2(inputs)\n",
        "        loss = loss_func(preds, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss\n",
        "        train_acc += accuracy(preds, labels)\n",
        "        \n",
        "    \n",
        "    net2.eval()\n",
        "    train_acc /= len(train_dl)\n",
        "    print(f\"train_acc: {train_acc}\")\n",
        "    #print(f\"Train Loss: {total_loss}\")\n",
        "    with torch.no_grad():\n",
        "        val_acc = 0\n",
        "        for inputs_test, labels_test in test_dl:\n",
        "            val_acc += accuracy(net2(inputs_test), labels_test)\n",
        "        val_acc /= len(test_dl)\n",
        "        print(f\"val_acc: {val_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GHoS9DJ8QB8"
      },
      "outputs": [],
      "source": [
        "accuracy(net2(mnist_test[0:8][0]), mnist_test[0:8][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4RBjQJg8QB9"
      },
      "outputs": [],
      "source": [
        "mnist_test[0:8][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0vsqBdJ8QB9"
      },
      "outputs": [],
      "source": [
        "mnist_test[0:8][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5jpKu828QB9"
      },
      "outputs": [],
      "source": [
        "len(test_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpkl9TIo8QB9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Neural Network from Scratch with PyTorch",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}